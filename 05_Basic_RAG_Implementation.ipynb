{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./data/AgenticAILLM.txt\")\n",
    "loaded_document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content='# Large Language Models in 2025 and Agentic AI:  Predictions and Potential\\n\\nThis document explores the anticipated state of Large Language Models (LLMs) in 2025 and the emerging field of Agentic AI. It covers potential advancements, challenges, and societal impacts.\\n\\n## I. Large Language Models in 2025:  Beyond the Hype\\n\\n**A. Expected Advancements:**\\n\\n1.  **Improved Contextual Understanding:**  LLMs will likely exhibit significantly improved contextual understanding, moving beyond simple pattern matching to a more nuanced grasp of meaning, intent, and implicit information.  This includes better handling of:\\n    *   Ambiguity:  Resolving ambiguous phrases and sentences more accurately.\\n    *   Long-Range Dependencies:  Maintaining coherence and consistency over very long texts (e.g., entire books or complex conversations).\\n    *   Common Sense Reasoning:  Demonstrating improved common sense and world knowledge, reducing nonsensical outputs.\\n    *   Nuance and Subtlety:  Better understanding of humor, sarcasm, and figurative language.\\n\\n2.  **Multimodal Capabilities:**  The integration of text with other modalities (images, audio, video) will become standard. This will lead to LLMs that can:\\n    *   Generate images from text descriptions with higher fidelity and creativity.\\n    *   Summarize videos or podcasts accurately.\\n    *   Create coherent narratives combining text and visual elements.\\n    *   Respond to multi-modal prompts (e.g., \"Describe the scene in this image and write a short story about it\").\\n\\n3.  **Enhanced Personalization and Customization:**  LLMs will become more adept at adapting to individual user preferences and styles.  This includes:\\n    *   Learning user writing styles to generate text that mimics them.\\n    *   Remembering past interactions to provide more relevant and personalized responses.\\n    *   Developing user-specific \"personas\" or \"agents\" with tailored knowledge and capabilities.\\n\\n4.  **Specialized LLMs:**  We\\'ll likely see a rise in LLMs trained on specific, narrow domains (e.g., legal contracts, medical research, software development) to achieve expert-level performance in those areas.  This will involve:\\n    *   Fine-tuning on large, high-quality, domain-specific datasets.\\n    *   Development of specialized evaluation metrics for these domains.\\n    *   Integration with domain-specific tools and databases.\\n\\n5.  **Increased Efficiency and Reduced Computational Cost:**  Research into more efficient architectures (e.g., sparse models, model distillation) and training methods will lead to:\\n    *   Smaller, faster, and less energy-intensive LLMs.\\n    *   Lower costs associated with training and deploying LLMs.\\n    *   Wider accessibility of LLM technology.\\n\\n**B. Challenges and Limitations:**\\n\\n1.  **Bias and Fairness:**  Addressing biases inherent in training data remains a critical challenge.  Efforts will focus on:\\n    *   Developing better techniques for detecting and mitigating bias.\\n    *   Creating more diverse and representative training datasets.\\n    *   Establishing ethical guidelines for LLM development and deployment.\\n\\n2.  **Truthfulness and Factuality:**  Ensuring that LLMs generate accurate and truthful information remains a significant hurdle.  This involves:\\n    *   Developing methods for grounding LLMs in external knowledge sources (e.g., knowledge graphs, databases).\\n    *   Improving techniques for fact-checking and verification.\\n    *   Distinguishing between factual claims and opinions.\\n\\n3.  **Explainability and Interpretability:**  Understanding how LLMs arrive at their outputs (the \"black box\" problem) is crucial for building trust and accountability.  Research will focus on:\\n    *   Developing methods for visualizing and interpreting LLM decision-making processes.\\n    *   Creating more transparent and explainable LLM architectures.\\n\\n4.  **Security and Misuse:**  The potential for LLMs to be used for malicious purposes (e.g., generating misinformation, deepfakes, phishing attacks) is a growing concern.  This requires:\\n    *   Developing robust methods for detecting and preventing LLM misuse.\\n    *   Establishing legal and regulatory frameworks to address these issues.\\n\\n5.  **Data Privacy:** Protecting the privacy of user data used to train and interact with LLMs will be of the utmost importance. Techniques will include:\\n    *   Federated learning\\n    *   Differential privacy\\n    *   Secure multi-party computation\\n\\n## II. Agentic AI:  LLMs Taking Action\\n\\n**A. Defining Agentic AI:**\\n\\nAgentic AI refers to AI systems, often powered by LLMs, that can autonomously plan, execute, and adapt to achieve complex goals in real-world environments.  Unlike traditional LLMs that primarily generate text, agentic AI systems can:\\n\\n*   **Interact with the world:**  Interact with software APIs, databases, websites, and even physical devices.\\n*   **Plan and Reason:**  Develop multi-step plans to achieve goals, reason about the consequences of actions, and adapt plans based on feedback.\\n*   **Learn and Improve:**  Continuously learn from their experiences and improve their performance over time.\\n*   **Collaborate:**  Potentially collaborate with other AI agents or humans to achieve shared goals.\\n\\n**B. Potential Applications:**\\n\\n1.  **Automated Workflows:**  Automating complex business processes that involve multiple steps and interactions with different systems.  Examples include:\\n    *   Automating customer support workflows.\\n    *   Managing supply chains and logistics.\\n    *   Scheduling meetings and managing calendars.\\n\\n2.  **Scientific Discovery:**  Accelerating scientific research by automating tasks such as:\\n    *   Literature review and hypothesis generation.\\n    *   Experimental design and data analysis.\\n    *   Drug discovery and materials science.\\n\\n3.  **Personal Assistants:**  Creating highly capable personal assistants that can handle a wide range of tasks, such as:\\n    *   Managing emails and communications.\\n    *   Booking travel and making reservations.\\n    *   Providing personalized recommendations and information.\\n\\n4.  **Software Development:**  Automating aspects of software development, such as:\\n    *   Code generation and debugging.\\n    *   Testing and quality assurance.\\n    *   Project management.\\n\\n5.  **Robotics and Automation:** Agentic AI will enhance the abilities of robots and automation to create more complex and valuable actions.\\n\\n**C. Challenges and Considerations:**\\n\\n1.  **Safety and Control:**  Ensuring the safety and reliability of agentic AI systems is paramount.  This requires:\\n    *   Developing robust mechanisms for monitoring and controlling agent behavior.\\n    *   Establishing clear boundaries and constraints for agent actions.\\n    *   Designing agents that can explain their reasoning and decisions.\\n\\n2.  **Ethical Implications:**  The potential for agentic AI to impact employment, autonomy, and social structures raises significant ethical questions.  These include:\\n    *   The impact on jobs and the workforce.\\n    *   The potential for bias and discrimination.\\n    *   The need for transparency and accountability.\\n\\n3.  **Coordination and Collaboration:**  Developing agentic AI systems that can effectively collaborate with each other and with humans is a complex challenge.\\n\\n4.  **Real-World Robustness:** Agentic systems need to handle unexpected events, noisy data, and incomplete information in real-world environments.\\n\\n5. **Evaluation and Benchmarking:** Clear standards for evaluting agentic AI, including performance, safety, and bias, are needed.\\n\\n## III. Conclusion: A Transformative Future\\n\\nLLMs and Agentic AI are poised to have a transformative impact on society in the coming years. While significant challenges remain, the potential benefits are immense.  Continued research, responsible development, and thoughtful consideration of ethical implications are crucial to ensuring that these technologies are used for the benefit of humanity. The ongoing dialogue between researchers, policymakers, and the public is essential to navigating this rapidly evolving landscape.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "chunks_of_text = text_splitter.split_documents(loaded_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vector_db = FAISS.from_documents(chunks_of_text, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1c654d608c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retriever.invoke(\"what are the Challenges and Considerations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content='1.  **Bias and Fairness:**  Addressing biases inherent in training data remains a critical challenge.  Efforts will focus on:\\n    *   Developing better techniques for detecting and mitigating bias.\\n    *   Creating more diverse and representative training datasets.\\n    *   Establishing ethical guidelines for LLM development and deployment.\\n\\n2.  **Truthfulness and Factuality:**  Ensuring that LLMs generate accurate and truthful information remains a significant hurdle.  This involves:\\n    *   Developing methods for grounding LLMs in external knowledge sources (e.g., knowledge graphs, databases).\\n    *   Improving techniques for fact-checking and verification.\\n    *   Distinguishing between factual claims and opinions.'),\n",
       " Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content='3.  **Explainability and Interpretability:**  Understanding how LLMs arrive at their outputs (the \"black box\" problem) is crucial for building trust and accountability.  Research will focus on:\\n    *   Developing methods for visualizing and interpreting LLM decision-making processes.\\n    *   Creating more transparent and explainable LLM architectures.\\n\\n4.  **Security and Misuse:**  The potential for LLMs to be used for malicious purposes (e.g., generating misinformation, deepfakes, phishing attacks) is a growing concern.  This requires:\\n    *   Developing robust methods for detecting and preventing LLM misuse.\\n    *   Establishing legal and regulatory frameworks to address these issues.\\n\\n5.  **Data Privacy:** Protecting the privacy of user data used to train and interact with LLMs will be of the utmost importance. Techniques will include:\\n    *   Federated learning\\n    *   Differential privacy\\n    *   Secure multi-party computation\\n\\n## II. Agentic AI:  LLMs Taking Action'),\n",
       " Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content=\"4.  **Specialized LLMs:**  We'll likely see a rise in LLMs trained on specific, narrow domains (e.g., legal contracts, medical research, software development) to achieve expert-level performance in those areas.  This will involve:\\n    *   Fine-tuning on large, high-quality, domain-specific datasets.\\n    *   Development of specialized evaluation metrics for these domains.\\n    *   Integration with domain-specific tools and databases.\\n\\n5.  **Increased Efficiency and Reduced Computational Cost:**  Research into more efficient architectures (e.g., sparse models, model distillation) and training methods will lead to:\\n    *   Smaller, faster, and less energy-intensive LLMs.\\n    *   Lower costs associated with training and deploying LLMs.\\n    *   Wider accessibility of LLM technology.\\n\\n**B. Challenges and Limitations:**\"),\n",
       " Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content='4.  **Software Development:**  Automating aspects of software development, such as:\\n    *   Code generation and debugging.\\n    *   Testing and quality assurance.\\n    *   Project management.\\n\\n5.  **Robotics and Automation:** Agentic AI will enhance the abilities of robots and automation to create more complex and valuable actions.\\n\\n**C. Challenges and Considerations:**\\n\\n1.  **Safety and Control:**  Ensuring the safety and reliability of agentic AI systems is paramount.  This requires:\\n    *   Developing robust mechanisms for monitoring and controlling agent behavior.\\n    *   Establishing clear boundaries and constraints for agent actions.\\n    *   Designing agents that can explain their reasoning and decisions.')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retriever.invoke(\"what are the Challenges and Considerations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content='1.  **Bias and Fairness:**  Addressing biases inherent in training data remains a critical challenge.  Efforts will focus on:\\n    *   Developing better techniques for detecting and mitigating bias.\\n    *   Creating more diverse and representative training datasets.\\n    *   Establishing ethical guidelines for LLM development and deployment.\\n\\n2.  **Truthfulness and Factuality:**  Ensuring that LLMs generate accurate and truthful information remains a significant hurdle.  This involves:\\n    *   Developing methods for grounding LLMs in external knowledge sources (e.g., knowledge graphs, databases).\\n    *   Improving techniques for fact-checking and verification.\\n    *   Distinguishing between factual claims and opinions.'),\n",
       " Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content='3.  **Explainability and Interpretability:**  Understanding how LLMs arrive at their outputs (the \"black box\" problem) is crucial for building trust and accountability.  Research will focus on:\\n    *   Developing methods for visualizing and interpreting LLM decision-making processes.\\n    *   Creating more transparent and explainable LLM architectures.\\n\\n4.  **Security and Misuse:**  The potential for LLMs to be used for malicious purposes (e.g., generating misinformation, deepfakes, phishing attacks) is a growing concern.  This requires:\\n    *   Developing robust methods for detecting and preventing LLM misuse.\\n    *   Establishing legal and regulatory frameworks to address these issues.\\n\\n5.  **Data Privacy:** Protecting the privacy of user data used to train and interact with LLMs will be of the utmost importance. Techniques will include:\\n    *   Federated learning\\n    *   Differential privacy\\n    *   Secure multi-party computation\\n\\n## II. Agentic AI:  LLMs Taking Action'),\n",
       " Document(metadata={'source': './data/AgenticAILLM.txt'}, page_content=\"4.  **Specialized LLMs:**  We'll likely see a rise in LLMs trained on specific, narrow domains (e.g., legal contracts, medical research, software development) to achieve expert-level performance in those areas.  This will involve:\\n    *   Fine-tuning on large, high-quality, domain-specific datasets.\\n    *   Development of specialized evaluation metrics for these domains.\\n    *   Integration with domain-specific tools and databases.\\n\\n5.  **Increased Efficiency and Reduced Computational Cost:**  Research into more efficient architectures (e.g., sparse models, model distillation) and training methods will lead to:\\n    *   Smaller, faster, and less energy-intensive LLMs.\\n    *   Lower costs associated with training and deploying LLMs.\\n    *   Wider accessibility of LLM technology.\\n\\n**B. Challenges and Limitations:**\")]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple use with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\"what are the Challenges and Considerations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Challenges and Considerations for LLM Development and Deployment:**\\n\\n* **Bias and Fairness:**\\n    * Detecting and mitigating bias in training data\\n    * Creating diverse and representative datasets\\n    * Establishing ethical guidelines\\n\\n* **Truthfulness and Factuality:**\\n    * Grounding LLMs in external knowledge sources\\n    * Fact-checking and verification\\n    * Distinguishing factual claims from opinions\\n\\n* **Explainability and Interpretability:**\\n    * Visualizing and interpreting LLM decision-making processes\\n    * Creating transparent and explainable architectures\\n\\n* **Security and Misuse:**\\n    * Detecting and preventing LLM misuse\\n    * Establishing legal and regulatory frameworks\\n\\n* **Data Privacy:**\\n    * Protecting user data used for training and interaction\\n    * Employing techniques like federated learning, differential privacy, and secure multi-party computation'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
